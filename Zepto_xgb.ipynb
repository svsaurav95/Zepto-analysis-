{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0a3c030-4313-43b9-9587-dd1f6e3f9b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c900bf-bdba-4ddb-a78a-603ac61343e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after preprocessing: (65258, 11)\n",
      "    product_atcs_30_days  product_atcs_plt_30_days  \\\n",
      "3                      0                         0   \n",
      "11                     0                         0   \n",
      "18                   899                      2647   \n",
      "24                   523                       523   \n",
      "35                    21                        27   \n",
      "\n",
      "    total_unique_orders_plt_30_days  product_ctr_city_30_days  \\\n",
      "3                                 0                  0.000000   \n",
      "11                                0                  0.098987   \n",
      "18                             1222                  0.029708   \n",
      "24                              246                  0.039907   \n",
      "35                               19                  0.019928   \n",
      "\n",
      "    query_product_similarity                    product_variant_id brand_name  \\\n",
      "3                   0.213126  13281002-f910-4ab9-8574-80ae35dc6fb9    Boldfit   \n",
      "11                  0.148046  3aa8671a-efc4-4900-97cc-442e761a91f6    Nandini   \n",
      "18                  0.132772  54bd7505-fb2a-4da3-a857-3e7637dec795     Garden   \n",
      "24                  0.554113  fc7c0c96-a564-4605-b69d-40d2912930b7  Unbranded   \n",
      "35                  0.751267  c2c5622c-9141-4991-a3e9-dfea9108c628    Khetika   \n",
      "\n",
      "          subcategory_name           category_name  \\\n",
      "3            Men's Topwear     Apparel & Lifestyle   \n",
      "11                    Milk     Dairy, Bread & Eggs   \n",
      "18                Namkeens                Munchies   \n",
      "24  Organics & Hydroponics     Fruits & Vegetables   \n",
      "35     Atta & Other Flours  Atta, Rice, Oil & Dals   \n",
      "\n",
      "                                 city_id  total_unique_orders  \n",
      "3   e92d0690-1df3-474b-9a5a-14e9761dfae3                    0  \n",
      "11  8ed26cb7-eb7d-4b7b-8d8c-3e93d5855bdd                    0  \n",
      "18  4f30407c-6a3c-4a4e-8a3d-652217d4b6cb                  454  \n",
      "24  056e834d-a1d2-4df3-a93d-7ebd60e6bb16                  246  \n",
      "35  4f30407c-6a3c-4a4e-8a3d-652217d4b6cb                   13  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\Dell\\Downloads\\data.csv\\data.csv\\updated_file.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop rows where 'product_name' repeats more than 10 times\n",
    "search_term_counts = df['product_name'].value_counts()\n",
    "repeating_terms = search_term_counts[search_term_counts > 10].index\n",
    "df = df[~df['product_name'].isin(repeating_terms)]\n",
    "\n",
    "# Initial feature selection\n",
    "initial_features = [\n",
    "    'product_atcs_30_days', 'product_atcs_plt_30_days', \n",
    "    'total_unique_orders_plt_30_days', 'product_ctr_city_30_days', \n",
    "    'query_product_similarity',  # Existing features\n",
    "    'product_variant_id', 'brand_name', 'subcategory_name', 'category_name', 'city_id'  # Categorical features\n",
    "]\n",
    "\n",
    "target_column = 'total_unique_orders'\n",
    "\n",
    "# Filter dataset to include selected features and target\n",
    "df = df[initial_features + [target_column]]\n",
    "\n",
    "# Fill missing values with median for numerical columns\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Remove top and bottom 5% outliers in the target column\n",
    "lower_bound = df[target_column].quantile(0.05)\n",
    "upper_bound = df[target_column].quantile(0.95)\n",
    "df = df[(df[target_column] >= lower_bound) & (df[target_column] <= upper_bound)]\n",
    "\n",
    "# Check dataset\n",
    "print(f\"Dataset shape after preprocessing: {df.shape}\")\n",
    "print(df.head())\n",
    "\n",
    "# Define categorical features for encoding\n",
    "categorical_features = ['product_variant_id', 'brand_name', 'subcategory_name', 'category_name', 'city_id']\n",
    "\n",
    "# Limit encoding for high-cardinality categories\n",
    "for col in categorical_features:\n",
    "    if col in df.columns:  # Ensure the column exists in the DataFrame\n",
    "        top_categories = df[col].value_counts().nlargest(10).index\n",
    "        df[col] = np.where(df[col].isin(top_categories), df[col], 'Other')\n",
    "\n",
    "# Sparse encoding for memory efficiency\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=True)\n",
    "X_categorical_sparse = encoder.fit_transform(df[categorical_features])\n",
    "\n",
    "\n",
    "# Numerical features and feature engineering\n",
    "X_numerical = df[\n",
    "    [\n",
    "        'product_atcs_30_days',\n",
    "        'product_atcs_plt_30_days',\n",
    "        'total_unique_orders_plt_30_days',\n",
    "        'product_ctr_city_30_days',\n",
    "        'query_product_similarity',\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# Feature engineering\n",
    "X_numerical['atcs_interaction'] = X_numerical['product_atcs_30_days'] * X_numerical['product_atcs_plt_30_days']\n",
    "X_numerical['log_total_unique_orders'] = np.log(X_numerical['total_unique_orders_plt_30_days'] + 1)\n",
    "X_numerical['ctr_similarity_interaction'] = (\n",
    "    X_numerical['product_ctr_city_30_days'] * X_numerical['query_product_similarity']\n",
    ")\n",
    "X_numerical['query_similarity_squared'] = X_numerical['query_product_similarity'] ** 2\n",
    "\n",
    "# Combine numerical and categorical features\n",
    "X = np.hstack([X_categorical_sparse.toarray(), X_numerical])\n",
    "y = df[target_column]  # Use the target column defined earlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d36530-892f-4b00-a41a-806169a803c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d9feb61-3d5e-48ee-8033-8b8376a9669c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of boosting rounds: 4500\n",
      "Official XGBoost R^2: 0.9945490956306458\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Prepare data\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'learning_rate': 0.35,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.5,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'lambda': 40,\n",
    "    'alpha': 0.6,\n",
    "    'gamma': 5.0,\n",
    "    'min_child_weight': 5,\n",
    "      \n",
    "}\n",
    "\n",
    "# Perform Cross-Validation\n",
    "cv_results = xgb.cv(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=4500,#4500\n",
    "    nfold=5,  #5, r - 25\n",
    "    metrics=['mae'],  # Metric to evaluate\n",
    "    early_stopping_rounds=950,  # 950\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Extract the best number of rounds\n",
    "best_num_boost_round = len(cv_results)\n",
    "print(f\"Best number of boosting rounds: {best_num_boost_round}\")\n",
    "\n",
    "# Train final model using the best number of rounds\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=best_num_boost_round)\n",
    "\n",
    "# Predict and evaluate on test set\n",
    "y_pred_xgb = xgb_model.predict(dtest)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"Official XGBoost R^2: {r2_xgb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e8098eb-6831-43c9-9e4e-4d7b74dd7586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Official XGBoost R^2: 0.9945490956306458\n",
      "Official XGBoost MAE: 2.854820966720581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "# Calculate MSE, RÂ², and MAE\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"Official XGBoost R^2: {r2_xgb}\")\n",
    "print(f\"Official XGBoost MAE: {mae_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb4ae0a-6395-4664-8852-7002c6a96117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35db9f3a-d1ac-4e54-8638-cfa2017bfdcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
